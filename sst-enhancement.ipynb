{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Make sure you are in your virtaul env and install below dependencies ! Uncomment !!**","metadata":{}},{"cell_type":"code","source":"# !pip install speechrecognition librosa numpy transformers pronouncing nltk soundfile wget   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T14:40:47.613148Z","iopub.execute_input":"2025-03-15T14:40:47.613450Z","iopub.status.idle":"2025-03-15T14:40:57.389694Z","shell.execute_reply.started":"2025-03-15T14:40:47.613412Z","shell.execute_reply":"2025-03-15T14:40:57.388316Z"}},"outputs":[{"name":"stdout","text":"Collecting speechrecognition\n  Downloading SpeechRecognition-3.14.1-py3-none-any.whl.metadata (31 kB)\nRequirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nCollecting pronouncing\n  Downloading pronouncing-0.2.0.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\nRequirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from speechrecognition) (4.12.2)\nRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\nRequirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\nRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\nRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\nRequirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\nRequirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\nRequirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\nRequirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nCollecting cmudict>=0.4.0 (from pronouncing)\n  Downloading cmudict-1.0.32-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.17.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\nRequirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.10/dist-packages (from cmudict>=0.4.0->pronouncing) (8.5.0)\nRequirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.10/dist-packages (from cmudict>=0.4.0->pronouncing) (5.13.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=5->cmudict>=0.4.0->pronouncing) (3.21.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\nDownloading SpeechRecognition-3.14.1-py3-none-any.whl (32.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hDownloading cmudict-1.0.32-py3-none-any.whl (939 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.4/939.4 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pronouncing\n  Building wheel for pronouncing (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pronouncing: filename=pronouncing-0.2.0-py2.py3-none-any.whl size=6233 sha256=e4d1339bb9a391702a262a478de421158c6096a0a09312bcd1003a6dd6928b7e\n  Stored in directory: /root/.cache/pip/wheels/05/f6/1d/599c67da1fa48c086d8c49e8fc6bd5f05bc9fa66fb04bed5db\nSuccessfully built pronouncing\nInstalling collected packages: speechrecognition, cmudict, pronouncing\nSuccessfully installed cmudict-1.0.32 pronouncing-0.2.0 speechrecognition-3.14.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import sys\n\n# Check and install missing modules\ntry:\n    import speech_recognition as sr\n    import librosa\n    import numpy as np\n    import transformers\n    import pronouncing\n    import nltk\n    import soundfile as sf\n    import os\n    import wget\n    import tarfile\n    import shutil\nexcept ModuleNotFoundError as e:\n    print(f\"Missing module: {e}\")\n    print(\"Please install it using: pip install {module_name}\".format(module_name=str(e).split(\"'\")[1]))\n    sys.exit(1)\n\n# Download required NLTK data\nnltk.download('cmudict')\n\nclass EnglishLearningTool:\n    def __init__(self):\n        self.recognizer = sr.Recognizer()\n        try:\n            self.nlp = transformers.pipeline(\"text-classification\", model=\"distilbert-base-uncased\")\n        except Exception as e:\n            print(f\"Error loading NLP model: {e}\")\n            sys.exit(1)\n        self.pronunciation_dict = cmudict.dict()\n        self.results = []\n\n    def download_dataset(self):\n        \"\"\"Download and extract a small LibriSpeech dataset\"\"\"\n        dataset_url = \"http://www.openslr.org/resources/12/dev-clean.tar.gz\"\n        dataset_path = \"dev-clean.tar.gz\"\n        extract_path = \"LibriSpeech\"\n\n        if not os.path.exists(extract_path):\n            print(\"Downloading LibriSpeech dataset...\")\n            try:\n                wget.download(dataset_url, dataset_path)\n                print(\"\\nExtracting dataset...\")\n                with tarfile.open(dataset_path, \"r:gz\") as tar:\n                    tar.extractall()\n                os.remove(dataset_path)\n            except Exception as e:\n                print(f\"Failed to download or extract dataset: {e}\")\n                return None\n        return extract_path\n\n    def analyze_audio(self, audio_path):\n        try:\n            audio_data, sample_rate = librosa.load(audio_path)\n            with sr.AudioFile(audio_path) as source:\n                audio = self.recognizer.record(source)\n                text = self.recognizer.recognize_google(audio)\n        except sr.UnknownValueError:\n            return \"Could not understand audio\", None\n        except sr.RequestError:\n            return \"API request failed\", None\n        except Exception as e:\n            return f\"Error loading audio: {e}\", None\n\n        stressed_words = self.detect_stress(audio_data, sample_rate, text)\n        return text, stressed_words\n\n    def detect_stress(self, audio_data, sample_rate, text):\n        pitches = librosa.pitch_tuning(audio_data)\n        intensity = librosa.feature.rms(y=audio_data)[0]\n        \n        words = text.split()\n        stressed_words = []\n        intensity_threshold = np.mean(intensity) + np.std(intensity)\n        chunks = len(intensity) // len(words)\n        \n        for i, word in enumerate(words):\n            chunk_start = i * chunks\n            chunk_end = (i + 1) * chunks\n            chunk_intensity = np.mean(intensity[chunk_start:chunk_end])\n            if chunk_intensity > intensity_threshold:\n                stressed_words.append(word)\n                \n        return stressed_words\n\n    def get_pronunciation(self, word):\n        if word.lower() in self.pronunciation_dict:\n            phones = self.pronunciation_dict[word.lower()][0]\n            return self.format_pronunciation(phones)\n        return \"Pronunciation not found\"\n\n    def format_pronunciation(self, phones):\n        stress_markers = {\"0\": \"\", \"1\": \"'\", \"2\": \"ˌ\"}\n        result = \"\"\n        for phone in phones:\n            if phone[-1].isdigit():\n                result += stress_markers[phone[-1]] + phone[:-1].lower()\n            else:\n                result += phone.lower()\n        return result\n\n    def correct_homophones(self, text):\n        homophones = {\n            \"their\": [\"there\", \"they're\"],\n            \"to\": [\"too\", \"two\"],\n            \"right\": [\"write\", \"rite\"],\n        }\n        \n        words = text.split()\n        corrected_text = []\n        for word in words:\n            if word.lower() in homophones:\n                context_score = self.nlp(f\"Is '{word}' appropriate in: {text}\")\n                if context_score[0]['score'] < 0.7:\n                    for alternative in homophones[word.lower()]:\n                        new_text = text.replace(word, alternative)\n                        score = self.nlp(f\"Is '{alternative}' appropriate in: {new_text}\")\n                        if score[0]['score'] > context_score[0]['score']:\n                            word = alternative\n                            break\n            corrected_text.append(word)\n            \n        return \" \".join(corrected_text)\n\n    def process_audio(self, audio_path):\n        text, stressed_words = self.analyze_audio(audio_path)\n        if not stressed_words:\n            return f\"Error processing {audio_path}: {text}\"\n\n        corrected_text = self.correct_homophones(text)\n        \n        output = [f\"File: {audio_path}\"]\n        output.append(f\"Original Text: {text}\")\n        output.append(f\"Corrected Text: {corrected_text}\")\n        output.append(\"Stressed Words and Pronunciation:\")\n        \n        for word in stressed_words:\n            pronunciation = self.get_pronunciation(word)\n            output.append(f\"- {word.upper()} : /{pronunciation}/\")\n            output.append(f\"  Breakdown: Pronounce as '{pronunciation.replace('ˈ', 'STRESS-')}'\")\n        \n        result = \"\\n\".join(output)\n        self.results.append(result)\n        return result\n\n    def test_dataset(self, dataset_path, max_files=5):\n        if not dataset_path:\n            print(\"Dataset not available. Aborting test.\")\n            return\n        \n        audio_files = []\n        for root, _, files in os.walk(dataset_path):\n            for file in files:\n                if file.endswith('.flac'):\n                    audio_files.append(os.path.join(root, file))\n                    if len(audio_files) >= max_files:\n                        break\n            if len(audio_files) >= max_files:\n                break\n\n        print(f\"Processing {len(audio_files)} audio files...\")\n        for audio_file in audio_files:\n            try:\n                result = self.process_audio(audio_file)\n                print(\"\\n\" + \"=\"*50)\n                print(result)\n                print(\"=\"*50)\n            except Exception as e:\n                print(f\"Error processing {audio_file}: {str(e)}\")\n\n        print(\"\\nSummary:\")\n        print(f\"Total files processed: {len(self.results)}\")\n        print(f\"Success rate: {(len(self.results) / len(audio_files)) * 100:.2f}%\")\n\ndef main():\n    tool = EnglishLearningTool()\n    \n    dataset_path = tool.download_dataset()\n    tool.test_dataset(dataset_path)\n    \n    cleanup = input(\"\\nRemove dataset files? (y/n): \")\n    if cleanup.lower() == 'y' and dataset_path:\n        shutil.rmtree(dataset_path)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T14:50:48.628771Z","iopub.execute_input":"2025-03-15T14:50:48.629745Z","iopub.status.idle":"2025-03-15T15:03:32.696007Z","shell.execute_reply.started":"2025-03-15T14:50:48.629708Z","shell.execute_reply":"2025-03-15T15:03:32.694902Z"}},"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"[nltk_data] Downloading package cmudict to /usr/share/nltk_data...\n[nltk_data]   Package cmudict is already up-to-date!\n","output_type":"stream"},{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"},{"name":"stdout","text":"Processing 5 audio files...\n\n==================================================\nFile: LibriSpeech/dev-clean/5536/43363/5536-43363-0001.flac\nOriginal Text: therefore he courts death in Battle on the other hand he would regard it as disgraceful to be killed in a private quarrel\nCorrected Text: therefore he courts death in Battle on the other hand he would regard it as disgraceful to be killed in a private quarrel\nStressed Words and Pronunciation:\n- THE : /dhah/\n  Breakdown: Pronounce as 'dhah'\n- IT : /'iht/\n  Breakdown: Pronounce as ''iht'\n==================================================\n\n==================================================\nFile: LibriSpeech/dev-clean/5536/43363/5536-43363-0009.flac\nOriginal Text: it is well known that the American Indian had somehow developed a cold power and although in the latter days there have been many imposters and allowing for the vanity and weakness of Human Nature it is fair to assume that there must have been some even in the old days yet there are well attested instances of remarkable prophecies and other mystic practice\nCorrected Text: it is well known that the American Indian had somehow developed a cold power and although in the latter days there have been many imposters and allowing for the vanity and weakness of Human Nature it is fair too assume that there must have been some even in the old days yet there are well attested instances of remarkable prophecies and other mystic practice\nStressed Words and Pronunciation:\n- WELL : /w'ehl/\n  Breakdown: Pronounce as 'w'ehl'\n- KNOWN : /n'own/\n  Breakdown: Pronounce as 'n'own'\n- ALTHOUGH : /ˌaoldh'ow/\n  Breakdown: Pronounce as 'ˌaoldh'ow'\n- IS : /'ihz/\n  Breakdown: Pronounce as ''ihz'\n- THE : /dhah/\n  Breakdown: Pronounce as 'dhah'\n==================================================\n\n==================================================\nFile: LibriSpeech/dev-clean/5536/43363/5536-43363-0016.flac\nOriginal Text: there are many trustworthy men and Men of Christian Faith to vouch for these and similar events occurring as for told\nCorrected Text: there are many trustworthy men and Men of Christian Faith to vouch for these and similar events occurring as for told\nStressed Words and Pronunciation:\n- MANY : /m'ehniy/\n  Breakdown: Pronounce as 'm'ehniy'\n- MEN : /m'ehn/\n  Breakdown: Pronounce as 'm'ehn'\n- AND : /ahnd/\n  Breakdown: Pronounce as 'ahnd'\n==================================================\n\n==================================================\nFile: LibriSpeech/dev-clean/5536/43363/5536-43363-0015.flac\nOriginal Text: 5 years later he repeated the service and again saved his people from awful slaughter\nCorrected Text: 5 years later he repeated the service and again saved his people from awful slaughter\nStressed Words and Pronunciation:\n- LATER : /l'eyter/\n  Breakdown: Pronounce as 'l'eyter'\n==================================================\n\n==================================================\nFile: LibriSpeech/dev-clean/5536/43363/5536-43363-0011.flac\nOriginal Text: this was carried out to the letter\nCorrected Text: this was carried out too the letter\nStressed Words and Pronunciation:\n- OUT : /'awt/\n  Breakdown: Pronounce as ''awt'\n==================================================\n\nSummary:\nTotal files processed: 5\nSuccess rate: 100.00%\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nRemove dataset files? (y/n):  n\n"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}